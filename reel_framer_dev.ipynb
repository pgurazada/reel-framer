{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd807a9520a047a0bdffb95ec1fdfd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1274ef60667849329fd74666749334e4",
              "IPY_MODEL_2acf96ddb22f4022a894c313ed45b49d",
              "IPY_MODEL_224d65d7dd3d4e7f99f348e4a33b99fc"
            ],
            "layout": "IPY_MODEL_f3d9e4ff648f49d1848a36acf46cf73d"
          }
        },
        "1274ef60667849329fd74666749334e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d70a58fadf4767b97857fac7bf7f5e",
            "placeholder": "​",
            "style": "IPY_MODEL_414390eff33e4f64a3a54aad88e27cff",
            "value": "mistral-7b-instruct-v0.2.Q5_K_M.gguf: 100%"
          }
        },
        "2acf96ddb22f4022a894c313ed45b49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03d72f9c1d5340c5980f34599ff4a1f5",
            "max": 5131409696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b03b076a6167491293ea9dcfe3b809e1",
            "value": 5131409696
          }
        },
        "224d65d7dd3d4e7f99f348e4a33b99fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b15b6565f0f34ccfa82c4e58784b3f02",
            "placeholder": "​",
            "style": "IPY_MODEL_626a102f36794f49b1b46491804bc8ff",
            "value": " 5.13G/5.13G [00:35&lt;00:00, 91.7MB/s]"
          }
        },
        "f3d9e4ff648f49d1848a36acf46cf73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d70a58fadf4767b97857fac7bf7f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "414390eff33e4f64a3a54aad88e27cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03d72f9c1d5340c5980f34599ff4a1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03b076a6167491293ea9dcfe3b809e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b15b6565f0f34ccfa82c4e58784b3f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "626a102f36794f49b1b46491804bc8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgurazada/reel-framer/blob/main/reel_framer_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9mO_0zA8mDa",
        "outputId": "3f2f02b3-80dd-411d-bceb-41643c3b26b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.23.tar.gz (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.23-cp310-cp310-manylinux_2_35_x86_64.whl size=8162245 sha256=789bb7d46def8373b42a229dd9afb3d8b9bc5e935572a5355e5de8b709977821\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/7c/23/5851b51f3b9088d6f7a5ba6d27b3494aa4940bf291b43ee04d\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: llama-cpp-python\n",
            "Successfully installed llama-cpp-python-0.2.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub"
      ],
      "metadata": {
        "id": "5bo62AvBoJY4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "from json import JSONDecodeError\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "pM2379DI8tQx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
        "model_basename = \"mistral-7b-instruct-v0.2.Q5_K_M.gguf\""
      ],
      "metadata": {
        "id": "DpDXlVhN6KmH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name_or_path,\n",
        "    filename=model_basename\n",
        ")"
      ],
      "metadata": {
        "id": "gN_Pv-yN9EXJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cd807a9520a047a0bdffb95ec1fdfd60",
            "1274ef60667849329fd74666749334e4",
            "2acf96ddb22f4022a894c313ed45b49d",
            "224d65d7dd3d4e7f99f348e4a33b99fc",
            "f3d9e4ff648f49d1848a36acf46cf73d",
            "23d70a58fadf4767b97857fac7bf7f5e",
            "414390eff33e4f64a3a54aad88e27cff",
            "03d72f9c1d5340c5980f34599ff4a1f5",
            "b03b076a6167491293ea9dcfe3b809e1",
            "b15b6565f0f34ccfa82c4e58784b3f02",
            "626a102f36794f49b1b46491804bc8ff"
          ]
        },
        "outputId": "73702497-926b-4c09-d45e-c4edac465f46"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-instruct-v0.2.Q5_K_M.gguf:   0%|          | 0.00/5.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd807a9520a047a0bdffb95ec1fdfd60"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The python interface to Llama CPP allows us to load the model binary (*.gguf) on a combination of CPU and GPU and provides an Open AI compatible serving interface."
      ],
      "metadata": {
        "id": "AOm8Lqwl7dh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU cores\n",
        "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    n_gpu_layers=43, # Change this value based on your model and your GPU VRAM pool.\n",
        "    n_ctx=8192 # Context window\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcbB2b3f9Hjn",
        "outputId": "916558d7-be87-46fb-b751-e153c55fc544"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general Mistral template for prompting is presented below (start of sentence token( `<s>`), instruction tokens (`[INST]`) and new lines (`\\n`) are important and should not be skipped in the template)."
      ],
      "metadata": {
        "id": "sv_iPu6c4yZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_prompt_template = \"\"\"<s>[INST]\n",
        "{system_message}\n",
        "\n",
        "{user_message} [/INST]\"\"\""
      ],
      "metadata": {
        "id": "z14QicsMVFo3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_json_info(info_row: str) -> dict:\n",
        "    \"\"\"\n",
        "    Fixes malformed JSON outputs from LLMs\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        info = json.loads(info_row)\n",
        "    except JSONDecodeError:\n",
        "        data = {\n",
        "        }\n",
        "        try:\n",
        "\n",
        "            for s in info_row.split('\",\"'):\n",
        "                if not s:\n",
        "                    continue\n",
        "                key, val = s.split(\":\", maxsplit=1)\n",
        "                key = key.strip().lstrip(\"{\").strip('\"')\n",
        "                val: str = re.sub('\"', '\\\\\"', val.lstrip('\"').strip('\\\"}'))\n",
        "                data[key] = val\n",
        "        except ValueError:\n",
        "            print(\"ERROR:\", info_row)\n",
        "        info = data\n",
        "    return info"
      ],
      "metadata": {
        "id": "gxDgW4PlH8X1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Extract News Information"
      ],
      "metadata": {
        "id": "VpuZlbF3tVFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_extractor_system_message = \"\"\"\n",
        "You are tasked to extract key information from news articles.\n",
        "You will be presented a news article that begins with ###News Article.\n",
        "\n",
        "Instructions:\n",
        "Extract the following items from the news article in the input in a JSON format:\n",
        "{\n",
        "    news setting: <Where did this news event take place?>,\n",
        "    news characters and their main activities: <List names of up to five main \\\n",
        "stakeholders in this news event and what they mainly did.>\n",
        "    news plot summary: <What happened in the news event?>\n",
        "    news information points: <What are the three most important things in this news story?>\n",
        "    news plot elements: <What are the four main plot points of the news story?>\n",
        "}\n",
        "To reiterate, your answer should be in the JSON format specified above.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "41KC_ezxUEqo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_user_message_template = \"\"\"###News Article \\n{news_article}\"\"\""
      ],
      "metadata": {
        "id": "s1pAjMe1UOZE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_article_input = \"\"\"\n",
        "The US Food and Drug Administration (USFDA) last week approved two breakthrough gene therapies — Casgevy by Vertex Pharmaceuticals and CRISPR Therapeutics, and Lyfgenia by Bluebird Bio — for sickle cell disease (SCD) in patients 12 years and older.\n",
        "\n",
        "The development marks a milestone medical advancement in treating a debilitating disease that primarily affects red blood cells’ capacity to carry adequate oxygen across the body, with the use of innovative cell-based gene therapies.\n",
        "Both approved products are made from patients’ own blood stem cells, which are modified, and are given back as a one-time, single-dose infusion as part of a hematopoietic (blood) stem cell transplant.\n",
        "\n",
        "Casgevy utilises CRISPR/Cas9 (Clustered Regularly Interspaced Short Palindromic Repeats-CRISPR associated) technology, a type of genome editing system.\n",
        "Emmanuelle Charpentier and Jennifer Doudna were awarded the Nobel Prize in Chemistry in 2020 for discovering CRISPR/Cas9 genetic scissors, called one of the gene technology’s sharpest tools.\n",
        "\n",
        "In India, which has the highest number of SCD carriers in the world, scientists associated with the Council for Scientific and Industrial Research-Institute of Genomics and Integrative Biology (CSIR-IGIB) have been working since 2018 to develop a gene therapy for SCD using the same technology.\n",
        "\n",
        "“After showing proof of the therapy developed in human-induced pluripotent stem cells (a particular potent type of stem cell that normally only exists during early embryonic development), we are now in preclinical stage of the therapy’s trial,” Debojyoti Chakraborty, lead scientist of the project at CSIR-IGIB, told ThePrint.\n",
        "\n",
        "The next step after the animal study, he said, is to start a phase-1 clinical trial for SCD patients in India, in partnership with the All India Institute of Medical Sciences (AIIMS) in Delhi and the department of science and technology after regulatory approvals for the therapy are in place.\n",
        "Once available in the country, the therapy can be a boon for millions of SCD patients in India which this year saw the launch of the National Sickle Cell Anaemia Elimination Mission — targeting to eliminate the disease by 2047.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ty9BRM7EUXgO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_for_news_extraction = mistral_prompt_template.format(\n",
        "    system_message=news_extractor_system_message,\n",
        "    user_message=news_user_message_template.format(\n",
        "        news_article=news_article_input\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "9TdlT6x7VKjh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = lcpp_llm(\n",
        "    prompt=prompt_for_news_extraction,\n",
        "    max_tokens=1024,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repeat_penalty=1.2,\n",
        "    echo=False\n",
        ")"
      ],
      "metadata": {
        "id": "euLrIribU02T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_extraction_output = get_json_info(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "ufOnAzPaVyJG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_extraction_output.keys()"
      ],
      "metadata": {
        "id": "6GkHurJwv992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e96d608-24eb-477c-bf56-8d1916dc3ff0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['news setting', 'news characters and their main activities', 'news plot summary', 'news information points', 'news plot elements'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Create a comedic analogy"
      ],
      "metadata": {
        "id": "8uIMAvrDvxWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comedic_analogy_prompt_template = \"\"\"\n",
        "You are tasked to create a comedic analogy based on key information extracted from a news article.\n",
        "\n",
        "Instructions:\n",
        "1. List three unique comedic analogies for the situation in the following story:\n",
        "{news_plot_summary}. Incorporate the following characters only: {news_characters_and_their_main_activities}.\n",
        "2. Decide the main characters of the news event as two of the most dominant characters in the summary: {news_plot_summary}\n",
        "3. To act out this analogous premise use the location mentioned here: {news_setting}\n",
        "\n",
        "Return your output as a JSON with the three analogies as keys like so:\n",
        "- Comedic Analogy 1: <first analogy>,\n",
        "- Comedic Analogy 2: <second analogy>,\n",
        "- Comedic Analogy 3: <third analogy>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Q7BRITTawOzD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_for_comedic_analogy = comedic_analogy_prompt_template.format(\n",
        "    news_plot_summary=news_extraction_output['news plot summary'],\n",
        "    news_characters_and_their_main_activities=news_extraction_output['news characters and their main activities'],\n",
        "    news_setting=news_extraction_output['news setting']\n",
        ")"
      ],
      "metadata": {
        "id": "H_1KktIXK0EZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_prediction_template = \"\"\"<s>[INST]{user_message}[/INST]\"\"\""
      ],
      "metadata": {
        "id": "BiVbknehZ7u-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = lcpp_llm(\n",
        "    prompt=mistral_prediction_template.format(\n",
        "        user_message=prompt_for_comedic_analogy\n",
        "    ),\n",
        "    max_tokens=1024,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repeat_penalty=1.2,\n",
        "    echo=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9PqCqQ3LQXt",
        "outputId": "6a186d84-6028-48e8-d42e-a768dafef953"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comedic_analogies = get_json_info(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "U7WgNxqPM_-u"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comedic_analogies.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O6NT4q1KdOg",
        "outputId": "ccf3721e-e3f8-449f-ac23-05514deb641c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Comedic Analogy 1', 'Comedic Analogy 2', 'Comedic Analogy 3'])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Create a script"
      ],
      "metadata": {
        "id": "xk3SW24XL7ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comedic_script_prompt_template = \"\"\"\n",
        "Write a script for a comedy skit about: {script_plot}. Cover the following information: {news_information_points}.\n",
        "The characters should be exactly: {news_characters_and_their_main_activities}.\n",
        "It should be set in {news_setting}. It should be entertaining.\n",
        "The dialogue should be colloquial and engaging. The dialogue should be 10 to 12 lines long.\n",
        "Each line of dialogue should be short - less than 20 words. End it with a punchline.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "y6yhSUFwL_eA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_for_comedic_script = comedic_script_prompt_template.format(\n",
        "    script_plot=comedic_analogies['Comedic Analogy 1'],\n",
        "    news_information_points=news_extraction_output['news information points'],\n",
        "    news_characters_and_their_main_activities=news_extraction_output['news characters and their main activities'],\n",
        "    news_setting=news_extraction_output['news setting']\n",
        ")"
      ],
      "metadata": {
        "id": "bv8R_dKdL_eB"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_prediction_template = \"\"\"<s>[INST]{user_message}[/INST]\"\"\""
      ],
      "metadata": {
        "id": "2_rjOV6TL_eB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = lcpp_llm(\n",
        "    prompt=mistral_prediction_template.format(\n",
        "        user_message=prompt_for_comedic_script\n",
        "    ),\n",
        "    max_tokens=1024,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repeat_penalty=1.2,\n",
        "    echo=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bdd799-62a4-4e1a-fc8f-88024d93adc5",
        "id": "i4YN-CESL_eB"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359f9695-60a3-47ea-c16a-d61e05644ac4",
        "id": "nOEz6XD6L_eC"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (Scene opens at the FDA headquarters, where Emmanuelle Charpentier and Jennifer Doudna are excitedly welcoming Vertex Pharmaceuticals and CRISPR Therapeutics)\n",
            "\n",
            "Emmanuelle: \"Hey there, long time no see! Welcome to your new home, Casgevy and CRISPR team!\" (Hands them a housewarming gift)\n",
            "\n",
            "Jennifer: \"Thanks Emmanuelle, we're thrilled to finally move in! And hey Bluebird Bio, nice to see you too!\"\n",
            "\n",
            "(Bluebird Bio enters with Lyfgenia in hand)\n",
            "\n",
            "Debojyoti (excitedly): \"Hello everyone, Deb from CSIR-IGIB here. I heard there's a new kid on the block! Hopefully AIIMS invites me to the next housewarming party.\"\n",
            "\n",
            "Vertex: \"Absolutely, Deb! We'll make sure you get an invite for your upcoming phase-1 trials!\"\n",
            "\n",
            "Emmanuelle: (Laughs) \"Well this is getting competitive. I guess we better start planning some FDA gene therapy cookouts then!\"\n",
            "\n",
            "Jennifer: \"You got it, Emmanuelle! And remember, let's make sure everyone plays nice and uses CRISPR/Cas9 technology correctly.\"\n",
            "\n",
            "Debojyoti: \"Agreed! No gene-editing shenanigans here!\"\n",
            "\n",
            "(They all laugh as the scene ends with a shot of them raising their mock gene therapy bottles in a toast)\n",
            "\n",
            "Vertex: \"To new beginnings, and no more sickle cell disease cases at our doorstep!\"\n",
            "\n",
            "Emmanuelle: \"Cheers to that! And remember, always double-check those CRISPR cuts.\" (They all laugh as the scene fades out)\n"
          ]
        }
      ]
    }
  ]
}